<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
  <title>Notes on \texttt{AllelicCapSeg}</title>
  <style type="text/css">code{white-space: pre;}</style>
  <script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
</head>
<body>
<div id="header">
<h1 class="title">Notes on <span class="math">\(\texttt{AllelicCapSeg}\)</span></h1>
</div>
<p>Some notes on the methods used in the current <code>python</code> implementation and proposed methods for the <code>hellbender</code> port.</p>
<h1 id="introduction">Introduction</h1>
<h1 id="recapseg-overview"><span class="math">\(\texttt{ReCapSeg}\)</span> Overview</h1>
<p>We first summarize the portions of the <span class="math">\(\texttt{ReCapSeg}\)</span> workflow that are generate the input for <span class="math">\(\texttt{AllelicCapSeg}\)</span>. The below is copied/paraphrased from the documentation at <a href="http://gatkforums.broadinstitute.org/discussion/5640/recapseg-overview">http://gatkforums.broadinstitute.org/discussion/5640/recapseg-overview</a>.</p>
<p><span class="math">\(\texttt{ReCapSeg}\)</span> is a copy-number–variant detector that runs on user-defined target regions, which can correspond to exomes, gene panels, or arbitrary windows. <span class="math">\(\texttt{ReCapSeg}\)</span> uses a Panel of Normal (PoN) samples to model noise and normalize the coverage calls of the target sample. These methods were designed for copy-number calling (amplification and deletion) of somatic events with a resolution of two or more targets. <span class="math">\(\texttt{ReCapSeg}\)</span> does not need a matched normal, but operates on a panel of normal samples representing similar library preparation to agnostically remove noise. <span class="math">\(\texttt{ReCapSeg}\)</span> is the production version of the <code>CapSeg</code> algorithm.</p>
<p>Given an DNA-Seq alignment BAM file and a BED file of target genomic intervals, the <span class="math">\(\texttt{ReCapSeg}\)</span> algorithms estimate copy ratio by performing the following steps:</p>
<ol>
<li><p>Generate proportional coverage: First, the per sample normalized coverage is calculated by normalizing the read coverage spanning a target segment with the total number of aligned reads (for every read group: number of reads over segment/total number of aligned reads). The proportional coverage is then calculated by normalizing every segment with the median normalized coverage across the PoN for the given segment.</p></li>
<li><p>Tangent normalization: This normalization procedure projects the sample proportional coverage to a hyperplane defined by the PoN. This normalization procedure results in a copy-ratio estimate with reduced noise.</p></li>
<li><p>Segment: The target regions are then merged into continuous segments that represent the same copy-number event. The segmentation is performed by a circular-binary-segmentation (CBS) algorithm described by Olshen et al. 2004 that was originally developed to segment noisy array copy-number data.<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a> Currently, <span class="math">\(\texttt{ReCapSeg}\)</span> considers only segments that include two or more targets (a target usually represents a single exon).</p></li>
</ol>
<p>To summarize, given coverage data for a set of targets, <span class="math">\(\texttt{ReCapSeg}\)</span> produces 1) <span class="math">\(\log_2\)</span> copy-ratio estimates for each target, and 2) corresponding segments, which are specified by a set of genomic intervals. The segment files produced by <span class="math">\(\texttt{ReCapSeg}\)</span> also contain segment “means,” which are given by <span class="math">\(\log_2\)</span> of the mean linear copy ratio of all targets contained within each segment.</p>
<h1 id="current-alleliccapseg-workflow">Current <span class="math">\(\texttt{AllelicCapSeg}\)</span> Workflow</h1>
<h2 id="segmented-model">Segmented model</h2>
<p><span class="math">\(\texttt{AllelicCapSeg}\)</span> uses allele-count data from heterozygous SNP sites to improve upon the segmented copy-number model given by <span class="math">\(\texttt{ReCapSeg}\)</span>. The <span class="math">\(\texttt{AllelicCapSeg}\)</span> model is characterized by a set of segment intervals and a set of model parameters; a model with <span class="math">\(N\)</span> segments is taken to have <span class="math">\(2N + 2\)</span> parameters</p>
<p><span class="math">\[\{\tau_1, f_1, \dots \tau_N, f_N, \sigma_g, \gamma\}\,.\]</span></p>
<p>Each individual segment labeled by <span class="math">\(i\)</span> is specified by its true copy ratio <span class="math">\(\tau_i\)</span> and its true minor allele fraction <span class="math">\(f_i\)</span> (referred to as the “minor homologous chromosome fraction” in the <code>python</code> code), yielding <span class="math">\(2N\)</span> parameters. Two additional global parameters <span class="math">\(\sigma_g\)</span> and <span class="math">\(\gamma\)</span> determine the variance of the copy ratio and the allele-fraction bias (referred to as the “skew”), respectively, for all segments.</p>
<p>Specifically, the variance of the copy ratio for targets in the <span class="math">\(i\)</span>th segment is assumed to be given by <span class="math">\(\sigma_i = \sigma_g \tau_i\)</span>. Furthermore, the allele-fraction bias <span class="math">\(\gamma\)</span> attempts to correct for a global discrepancy between the measured and true allele fractions, which may be induced by effects such as reference bias during alignment. It is defined such that a balanced true allele fraction of <span class="math">\(f = 1/2\)</span> will yield, on average, an observed minor allele fraction of <span class="math">\(\gamma/2\)</span>; we shall expand on this definition below.</p>
<h2 id="identifying-normal-heterozygous-snp-sites">Identifying normal heterozygous SNP sites (het pulldown)</h2>
<p>The main idea behind <span class="math">\(\texttt{AllelicCapSeg}\)</span> is to use allele-count data at heterozygous SNP sites to infer copy number; these sites should exhibit balanced reference/alternate read counts in the normal sample, but unbalanced copy-number events could measurably alter this balance in the tumor sample. Thus, the first step in the <span class="math">\(\texttt{AllelicCapSeg}\)</span> workflow is to identify the heterozygous SNP sites that will be leveraged in the rest of the analysis.</p>
<p>We first start with a list of common SNP sites, and consider all reads passing a quality-score filter (taking a default minimum quality of 0). We examine the allele counts at these sites in the normal sample, and discard those sites that appear to be homozygous by performing a two-tailed binomial test on the counts at each site.</p>
<p>Specifically, for a SNP site labeled by <span class="math">\(k\)</span>, let the reference and alternate counts be <span class="math">\(A_k\)</span> and <span class="math">\(B_k\)</span>, respectively; also, let the major and minor allele counts be <span class="math">\(M_k\)</span> and <span class="math">\(m_k\)</span>, respectively. The total counts are denoted by <span class="math">\(N_k = A_k + B_k = M_k + m_k\)</span>.<a href="#fn2" class="footnoteRef" id="fnref2"><sup>2</sup></a></p>
<p>For sites above a read-count threshold <span class="math">\(N_k \geq 10\)</span>, the compatibility of the major allele count <span class="math">\(M_k\)</span> and the total count <span class="math">\(N_k\)</span> with the null hypothesis of a allele fraction <span class="math">\(f\)</span> (assumed to be the same across all sites, with a default value of <span class="math">\(f = 1/2\)</span> used) is checked with a two-tailed binomial test; a <span class="math">\(p\)</span>-value threshold of 0.05 is assumed. Sites with counts below the threshold or incompatible with the allele fraction <span class="math">\(f\)</span> (i.e., likely to be homozygous SNPs) are filtered out.</p>
<p>The remaining sites are assumed to be heterozygous SNPs. The allele counts <span class="math">\(\{A_k, B_k\}\)</span> at these sites are pulled from the tumor sample and stored.</p>
<h2 id="initializing-the-model">Initializing the model</h2>
<p>The initial state of the model is based on the result from <span class="math">\(\texttt{ReCapSeg}\)</span>. The set of segment intervals is set to those found by <span class="math">\(\texttt{ReCapSeg}\)</span>, and the <span class="math">\(\tau_i\)</span> are set to the median copy ratio of all targets contained within each <span class="math">\(i\)</span>th segment (note that these differ from the aforementioned segment “means” returned by <span class="math">\(\texttt{ReCapSeg}\)</span>, which are not used by <span class="math">\(\texttt{AllelicCapSeg}\)</span>). Initial values of <span class="math">\(\sigma_g = 0.15\)</span> and <span class="math">\(\gamma = 2 \times 0.48 = 0.96\)</span> are used for the global parameters.</p>
<p>Initialization of the minor homologous chromosome fractions <span class="math">\(f_i\)</span> for each segment is more involved. This is accomplished on a per segment basis by taking <span class="math">\(f_i\)</span> to be the single parameter in a beta-binomial mixture model and selecting the value that maximizes the corresponding likelihood function. Recall that the beta-binomial distribution gives the probability for the number of successes <span class="math">\(k\)</span> out of a number of trials <span class="math">\(n\)</span>, where the probability of success for each trial is a random variable that follows a beta distribution with parameters <span class="math">\(\alpha\)</span> and <span class="math">\(\beta\)</span>. The probability distribution is</p>
<p><span class="math">\[p_{\beta\text{-bin}}(k | n, \alpha, \beta) = {n \choose k} \frac{B(k+\alpha, n-k+\beta)}{B(\alpha, \beta)}\,,\]</span></p>
<p>where <span class="math">\(B(\alpha, \beta)\)</span> is the Euler beta function.</p>
<p>Consider a segment labeled by <span class="math">\(i\)</span>, and let <span class="math">\(D_i = \{A_{k_i}, B_{k_i}, \dots , A_{k_i+K_i}, B_{k_i+K_i}\}\)</span> be the data set of tumor-sample allele counts for the <span class="math">\(K_i\)</span> heterozygous SNP sites (i.e., those identified in the het pulldown step) contained within this segment. The likelihood function for the allele fraction <span class="math">\(f_i\)</span> of this segment, given the data set <span class="math">\(D_i\)</span>, is taken to be</p>
<p><span class="math">\[\label{allele-frac-ll}
\mathcal{L}(f_i | D_i) = p(D_i | f_i) = 
\begin{cases}
1\,, &amp; D_i = \{\}\,, \\
\prod_{k = k_i}^{k_i + K_i} \left\{\frac{1}{2}(1-w)\left[\mathcal{L}_\text{ref}(f_i | A_k, B_k) + \mathcal{L}_\text{alt}(f_i | A_k, B_k)\right] + w\mathcal{L}_\text{out}\right\}\,, &amp; \text{otherwise}\,.
\end{cases}\]</span></p>
<p>Here, <span class="math">\(w\)</span> is a weight parameter that will be later be used to account for outliers via the addition of a uniform-distribution component to the mixture model, which is represented in the likelihood by the <span class="math">\(\mathcal{L}_\text{out}\)</span> term; for this initialization stage, <span class="math">\(w = 0\)</span> is chosen.<a href="#fn3" class="footnoteRef" id="fnref3"><sup>3</sup></a></p>
<p>Furthermore, <span class="math">\(\mathcal{L}_\text{ref}(f_i | A_k, B_k)\)</span> is the likelihood of the minor allele fraction <span class="math">\(f_i\)</span>, given allele counts <span class="math">\(\{A_k, B_k\}\)</span> at SNP site <span class="math">\(k\)</span>, for the case of a reference minor allele (i.e., <span class="math">\(A_k \leq B_k\)</span>). It is given by</p>
<p><span class="math">\[\mathcal{L}_\text{ref}(f_i | A_k, B_k) =
\begin{cases}
1\,, &amp; f_i = 0~\text{and}~A_i = 0\,, \\
p_{\beta\text{-bin}}(B_k | A_k+B_k, \alpha_\text{ref}(f_i), \beta_\text{ref}(f_i))\,, &amp; \text{otherwise}\,.
\end{cases}\]</span></p>
<p>Here,</p>
<p><span class="math">\[\alpha_\text{ref}(f_i) = \left(1 - \frac{f_i}{\gamma}\right) \Sigma\,, \qquad
\beta_\text{ref}(f_i) = \frac{f_i\Sigma}{\gamma}\,,\]</span></p>
<p>where the parameter <span class="math">\(\Sigma\)</span> accounts for overdispersion and is fit to a panel of normal samples, yielding</p>
<p><span class="math">\[\Sigma = \exp(s_0 + s_1\gamma/2)\,, \qquad
s_0 = -33.67232\,,\quad
s_1 = 82.77464\,.\]</span></p>
<p>Similarly, <span class="math">\(\mathcal{L}_\text{alt}(f_i | A_k, B_k)\)</span> is the likelihood of <span class="math">\(f_i\)</span>, given allele counts <span class="math">\(\{A_k, B_k\}\)</span> at SNP site <span class="math">\(k\)</span>, for the case of an alternate minor allele (i.e., <span class="math">\(B_k \leq A_k\)</span>). It is given by</p>
<p><span class="math">\[\mathcal{L}_\text{alt}(f_i | A_k, B_k) =
p_{\beta\text{-bin}}(B_k | A_k+B_k, \alpha_\text{alt}(f_i), \beta_\text{alt}(f_i))\,,\]</span></p>
<p>with</p>
<p><span class="math">\[\alpha_\text{alt}(f_i) = f_i\gamma\Sigma\,, \qquad
\beta_\text{alt}(f_i) = \left(1 - f_i\gamma\right) \Sigma\,.\]</span></p>
<p>In practice, the maximum-likelihood estimate for <span class="math">\(f_i\)</span> is found by using the <code>scipy</code> implementation of the L-BFGS-B optimization algorithm to minimize the negative log-likelihood function, requiring convergence to machine precision. An initial guess of <span class="math">\(f_i = 0.25\)</span> is used, with the allowed range taken to be <span class="math">\(10^{-10} \leq f_i \leq 0.5\)</span>.</p>
<h2 id="initial-optimization-of-allelic-fraction-bias">Initial optimization of allelic-fraction bias</h2>
<h2 id="snp-segmentation">SNP segmentation</h2>
<p>Using the initial value of <span class="math">\(\gamma\)</span> found in the previous step, SNPs and their corresponding reference/alternate read counts are transformed to targets with corresponding effective “copy ratios,” which are then segmented using the <code>DNACopy</code> CBS implementation. However, these effective copy ratios will not scale with the copy number as would a true copy ratio, and hence should not be thought of as such.</p>
<p>In particular, for a SNP site indexed by <span class="math">\(k\)</span> with allele counts <span class="math">\(\{A_k, B_k\}\)</span>, the effective copy ratio <span class="math">\(\tilde\tau_k \)</span> is taken to be</p>
<p><span class="math">\[\tilde\tau_k =\left |\frac{B_k}{A_k + B_k} - \frac{\gamma}{2}\right|\,.\]</span></p>
<p>The idea here is that the quantity <span class="math">\(B_k / (A_k + B_k) - \gamma / 2\)</span> will be clustered around zero for sites <span class="math">\(k\)</span> contained in segments <span class="math">\(i\)</span> where the true minor allele fraction is <span class="math">\(f_i = 1/2\)</span>, but will generally form two clusters centered at <span class="math">\(\pm\)</span> , with the positive and negative signs corresponding to sites with reference and alternate minor alleles, respectively. By taking the effective copy ratio passed to CBS to be the absolute value of this quantity, we are simply folding the data vertically before segmenting. As with the segmentation of targets in <span class="math">\(\texttt{ReCapSeg}\)</span>, the <code>DNACopy</code> parameter <code>data.type</code> is set to <code>logratio</code>.</p>
<h2 id="targetsnp-segment-union">Target/SNP segment union</h2>
<h2 id="small-segment-merging">Small-segment merging</h2>
<p>Using CBS to segment the targets in <span class="math">\(\texttt{ReCapSeg}\)</span> results in segments that are larger than <span class="math">\(\sim\)</span>2–3 targets. However, after taking the union of target and SNP segments, small segments with less than <span class="math">\(\sim\)</span>2–3 targets may be introduced. To be consistent with CBS and <span class="math">\(\texttt{ReCapSeg}\)</span>, <span class="math">\(\texttt{AllelicCapSeg}\)</span> treats these small segments as spurious, and removes them by merging them with adjacent segments.</p>
<p>A segment is considered to be small if the number of targets it contains is strictly less than a threshold number of targets <span class="math">\(n_t\)</span>; we take <span class="math">\(n_t = 3\)</span>. The small-segment merging algorithm checks each <span class="math">\(i\)</span>th segment in turn, starting with the first, leftmost segment. If the segment is small, it is repeatedly merged with the adjacent segment that is closer in the <span class="math">\(L_1\)</span> distance <span class="math">\(|\tau_i - \tau_{i \pm 1}| + |f_i - f_{i \pm 1}|\)</span> in copy-ratio–allele-fraction space until it is no longer small.<a href="#fn4" class="footnoteRef" id="fnref4"><sup>4</sup></a> Exceptions occur for adjacent segments on different chromosomes, which are never merged; in practice, this is enforced by setting the <span class="math">\(L_1\)</span> distance between segments on different chromosomes to be infinite. After all segments have been checked and merged, any remaining small segments (which will be present if any chromosome contains less than <span class="math">\(n_t\)</span> targets) are dropped.</p>
<h2 id="parameter-optimization">Parameter optimization</h2>
<h2 id="similar-segment-merging">Similar-segment merging</h2>
<h2 id="final-parameter-optimization">Final parameter optimization</h2>
<h1 id="proposed-methods-for-texttthellbender">Proposed Methods for <span class="math">\(\texttt{hellbender}\)</span></h1>
<h2 id="bayesian-het-pulldown">Bayesian het pulldown</h2>
<h2 id="likelihood-based-segment-merging">Model-comparison test for segment merging</h2>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>Specifically, the CBS implementation provided by the <code>R</code> package <code>DNACopy</code> is used. Note that even though the <code>DNACopy</code> parameter <code>data.type</code> is set to <code>logratio</code>, the tangent-normalized <em>linear</em> copy ratios are used instead.<a href="#fnref1">↩</a></p></li>
<li id="fn2"><p>Note that the “alternate” and “minor” counts are simply found by subtracting the reference and major counts from the total count, respectively; this lumps stray reads that do not actually match the alternate or minor alleles into both of these categories. In principle, we could easily take only the largest and second-largest counts and discard the rest, but this is not what is currently implemented.<a href="#fnref2">↩</a></p></li>
<li id="fn3"></li>
<li id="fn4"><p>To be explicit, segments are reindexed after each merge, so that the new segment formed by merging segment <span class="math">\(i\)</span> and segment <span class="math">\(i \pm 1\)</span> retains the index <span class="math">\(i\)</span>.<a href="#fnref4">↩</a></p></li>
</ol>
</div>
</body>
</html>
